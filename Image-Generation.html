<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc-markdown-css-theme" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Image Generation</title>
  <style>
  /*
  To be used for Custom CSS, kept separate to distinguish it from Stylses sourced elsewhere
  */

  img {
      max-width: 100%;
  }

  a[forTitle="index"] {
      display: none;
  }

  nav li>a:not(:only-child)::before {
      font-size: 1.25em;
  }
  </style>
  <style>
  :root {
    --solarized-base03:  #002b36;
    --solarized-base02:  #073642;
    --solarized-base01:  #586e75;
    --solarized-base00:  #657b83;
    --solarized-base0:   #839496;
    --solarized-base1:   #93a1a1;
    --solarized-base2:   #eee8d5;
    --solarized-base3:   #fdf6e3;
    --solarized-yellow:  #b58900;
    --solarized-orange:  #cb4b16;
    --solarized-red:     #dc322f;
    --solarized-magenta: #d33682;
    --solarized-violet:  #6c71c4;
    --solarized-blue:    #268bd2;
    --solarized-cyan:    #2aa198;
    --solarized-green:   #859900;
  }

  @media (prefers-color-scheme: dark) {
    :root {
      --solarized-base03: #fdf6e3;
      --solarized-base02: #eee8d5;
      --solarized-base01: #93a1a1;
      --solarized-base00: #839496;
      --solarized-base0:  #657b83;
      --solarized-base1:  #586e75;
      --solarized-base2:  #073642;
      --solarized-base3:  #002b36;
    }
  }

  pre, pre.numberSource {
    background: var(--solarized-base3);
    /* border: 1px solid var(--solarized-base2); */
    --color-code-highlight-bg: var(--solarized-base2);
  }
  pre code { color: var(--solarized-base00); }
  pre.numberSource > code.sourceCode > span > a:first-child::before {
    color: var(--solarized-base1);
  }
  code span.kw { color: var(--solarized-green);  font-weight: normal; font-style: normal; } /* Keyword */
  code span.dt { color: var(--solarized-yellow); font-weight: normal; font-style: normal; } /* DataType */
  code span.dv { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* DecVal */
  code span.bn { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* BaseN */
  code span.fl { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* Float */
  code span.ch { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* Char */
  code span.st { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* String */
  code span.co { color: var(--solarized-base1);  font-weight: normal; font-style: italic; } /* Comment */
  code span.ot { color: var(--solarized-blue);   font-weight: normal; font-style: normal; } /* Other */
  code span.al { color: var(--solarized-red);    font-weight: normal; font-style: normal; } /* Alert */
  code span.fu { color: var(--solarized-blue);   font-weight: normal; font-style: normal; } /* Function */
  code span.er { color: var(--solarized-red);    font-weight: normal; font-style: normal; } /* Error */
  code span.wa { color: var(--solarized-orange); font-weight: normal; font-style: italic; } /* Warning */
  code span.cn { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* Constant */
  code span.sc { color: var(--solarized-red);    font-weight: normal; font-style: normal; } /* SpecialChar */
  code span.vs { color: var(--solarized-cyan);   font-weight: normal; font-style: normal; } /* VerbatimString */
  code span.ss { color: var(--solarized-red);    font-weight: normal; font-style: normal; } /* SpecialString */
  code span.im { color: var(--solarized-base00); font-weight: normal; font-style: normal; } /* Import */
  code span.va { color: var(--solarized-blue);   font-weight: normal; font-style: normal; } /* Variable */
  code span.cf { color: var(--solarized-green);  font-weight: normal; font-style: normal; } /* ControlFlow */
  code span.op { color: var(--solarized-green);  font-weight: normal; font-style: normal; } /* Operator */
  code span.bu { color: var(--solarized-base00); font-weight: normal; font-style: normal; } /* BuiltIn */
  code span.ex { color: var(--solarized-base00); font-weight: normal; font-style: normal; } /* Extension */
  code span.pp { color: var(--solarized-orange); font-weight: normal; font-style: normal; } /* Preprocessor */
  code span.at { color: var(--solarized-base00); font-weight: normal; font-style: normal; } /* Attribute */
  code span.do { color: var(--solarized-base1);  font-weight: normal; font-style: italic; } /* Documentation */
  code span.an { color: var(--solarized-base1);  font-weight: normal; font-style: italic; } /* Annotation */
  code span.cv { color: var(--solarized-base1);  font-weight: normal; font-style: italic; } /* CommentVar */
  code span.in { color: var(--solarized-base1);  font-weight: normal; font-style: italic; } /* Information */
  a.sourceLine::before { text-decoration: none; }

  /* pandoc diff mode */
  code.diff span.kw { color: var(--solarized-yellow); font-weight: normal; font-style: normal; } /* --- lines */
  code.diff span.dt { color: var(--solarized-blue);   font-weight: normal; font-style: normal; } /* +++ lines, @@ ... @@ lines */
  code.diff span.st { color: var(--solarized-red);    font-weight: normal; font-style: normal; } /* - lines */
  code.diff span.va { color: var(--solarized-green);  font-weight: normal; font-style: normal; } /* + lines */

  </style>
  <style>

  /* ----- Global settings ----------------------------------------------- {{{ */

  :root {
    /* --- Colors --- */
    --background-color: #161313;

    --color-text: #f7f5f2;
    --color-text-secondary: #9d9b99;
    --color-link: #bc805d;
    --color-sidenote: #b4b2af;

    --highlight-red: #660000;
    --highlight-yellow: #7f6000;
    --highlight-green: #274e13;
    --highlight-blue: #1c4587;
    --highlight-purple: #351c75;

    --color-inline-code: #f7f5f2;
    --color-inline-code-bg: #062b35;

    --color-border: #393635;
    --color-border-heavy: #524f4d;

    --color-table-heading: #242121;

    /* --- Text --- */

    --font-family-prose: system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Open Sans","Helvetica Neue",sans-serif;
    --font-family-heading: system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Open Sans","Helvetica Neue",sans-serif;
    --font-family-code: Menlo, monospace;
    --side-note-number-font-family: var(--font-family-prose);

    --line-height: 26px;
    --font-size: 17px;

    --inline-code-font-size: 15px;
    --code-block-font-size: 14px;
    --code-block-side-padding: 8px;
    --line-numbers-font-size: 12px;

    --tight-code-line-height: 18px;
    --tight-code-padding-top: 5px;

    --side-note-line-height: 20px;
    --side-note-font-size: 13px;
    --side-note-code-font-size: 13px;
    --side-note-baseline-offset: 4px;
    --side-note-sup-offset: -6px;
    --side-note-number-hang-left: -6px;
    --side-note-text-indent: -9px;

    --heading-font-weight: 500;

    --title-font-size: 42px;
    --title-code-font-size: 40px;
    --title-line-height: 48px;
    --title-margin-top: 92px;

    --h1-font-size: 32px;
    --h1-code-font-size: 29px;
    --h1-line-height: 36px;
    --h1-word-spacing: 1px;
    --h1-margin-top: 30px;
    --h1-margin-bottom: 12px;

    --h2-font-size: 22px;
    --h2-code-font-size: 20px;
    --h2-line-height: 28px;
    --h2-word-spacing: 0.5px;
    --h2-margin-top: 18px;
    --h2-margin-bottom: 6px;

    --ul-indent-size: 23px;
    --ol-indent-size: 19px;
    --ol-li-padding-left: 4px;

    --hr-margin-top: 18px;
    --hr-margin-bottom: calc(var(--line-height) - var(--hr-margin-top) - 1px);

    --extra-wide-scale-factor: 1.5;

    --figcaption-line-height: 21px;
    --figcaption-font-size: 14px;
    --figcaption-code-font-size: 13px;
    --figcaption-gap: 6px;
    --captioned-figure-gap: 10px;

    --table-line-height: 21px;
    --table-font-size: 14px;
    --table-code-font-size: 13px;

    --nav-toc-font-size: 12px;
    --nav-toc-code-font-size: 12px;
    --nav-toc-indent: 15px;
    --nav-toc-baseline-offset: 2px;

    /* --- Layout --- */

    --main-width: 745px * 2;
    /* The name doesn't indicate it, but this variable actually specifies an
     * effective minimum width. (It didn't previously behave this way, but the
     * change to do so was made in a backwards-compatible way, so the variable
     * was not renamed.)
     **/
    --main-width-narrow: 550px;
    --side-note-max-width: 300px;

  }


  *, *:after, *:before {
    box-sizing: border-box;
    margin: 0;
    -webkit-tap-highlight-color: rgba(0,0,0,0);
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
  }

  html {
    /* https://github.com/edwardtufte/tufte-css/issues/81#issuecomment-261953409 */
    -webkit-text-size-adjust: 100%;
  }

  body {
    font-family: var(--font-family-prose);
    color: var(--color-text);
    font-size: var(--font-size);
    line-height: var(--line-height);
    -webkit-font-variant-ligatures: no-common-ligatures;
    font-variant-ligatures: no-common-ligatures;

    /* Safari-only right now (macOS, iOS) but looks so good. */
    hanging-punctuation: first;

    margin: 0;
    padding: 0;
    padding-top: var(--title-margin-top);
    width: 100%;

    background-color: var(--background-color);
  }

  @media print {
    body {
      background-color: initial;
    }
  }

  /* }}} */
  /* ----- Utility classes -----------------------------------------------  {{{ */
  .only-light-mode {
    display: inherit;
  }
  .only-dark-mode {
    display: none;
  }

  @media (prefers-color-scheme: dark) {
    .only-light-mode {
      display: none;
    }
    .only-dark-mode {
      display: inherit;
    }
  }
  /* }}} */
  /* ----- Side notes and margin notes ----------------------------------- {{{ */
  /* --- Side note text and numbering --- {{{ */

  .sidenote,
  .marginnote {
    color: var(--color-sidenote);

    font-size: var(--side-note-font-size);
    line-height: var(--side-note-line-height);
    vertical-align: baseline;

    /* Align first baseline to body. */
    margin-top: var(--side-note-baseline-offset);
  }

  .sidenote code,
  .marginnote code {
    color: var(--color-sidenote);
  }

  main {
    counter-reset: sidenote-counter;
  }

  .sidenote-number {
    counter-increment: sidenote-counter;
  }

  .sidenote-number:after,
  .sidenote:before {
    content: counter(sidenote-counter);
    position: relative;
  }

  nav#TOC label,
  label.margin-toggle:not(.sidenote-number),
  .sidenote-number:after,
  .sidenote:before,
  .footnote-ref sup,
  sup {
    font-size: var(--side-note-font-size);
    font-weight: 700;
    font-family: var(--side-note-number-font-family);
    -webkit-font-feature-settings: "tnum" 1;
    font-feature-settings: "tnum" 1;

    /* Mimic 'vertical-align: super' (browser style for sup tag)
     * without causing a gap in our text's implicit grid. */
    vertical-align: baseline;
    position: relative;
    top: var(--side-note-sup-offset);
  }

  sup {
    font-weight: inherit;
  }

  /* Make the superscript hang. */
  .sidenote:before { left: var(--side-note-number-hang-left); }
  /* Get first first column of first row to line up with other rows. */
  .sidenote { text-indent: var(--side-note-text-indent); }

  /*}}} */
  /* --- Side note input controls --- {{{ */

  input.margin-toggle {
      display: none;
  }
  label.margin-toggle:not(.sidenote-number) {
      display: none;
  }
  label.sidenote-number {
      display: inline;
  }

  /* Unfortunately, variables aren't in scope here.
   * See calculations in Horizontal layouting.
   */
  @media screen and (max-width: calc(26px + 550px + 26px + 169px + 26px - 1px)) {
    .margin-toggle:checked + .sidenote,
    .margin-toggle:checked + .marginnote {
      margin-top: var(--side-note-line-height);
      vertical-align: baseline;
    }

    label.margin-toggle {
      color: var(--color-link);
    }

    label.margin-toggle:not(.sidenote-number) {
      display: inline;
    }

    label {
      cursor: pointer;
    }
  }

  /* }}} */
  /* }}} */
  /* ----- Headings ------------------------------------------------------ {{{ */

  h1, h2 {
    font-family: var(--font-family-heading);
    font-weight: var(--heading-font-weight);
  }

  h4, h5, h6 {
    font-weight: normal;
  }

  h1.title {
    margin-top: var(--line-height);
    margin-bottom: var(--line-height);
    font-size: var(--title-font-size);
    line-height: var(--title-line-height);
  }

  h1.title code {
    font-size: var(--title-code-font-size);
  }

  h1:not(.title) {
    font-size: var(--h1-font-size);
    line-height: var(--h1-line-height);
    word-spacing: var(--h1-word-spacing);

    margin-top: var(--h1-margin-top);
    margin-bottom: var(--h1-margin-bottom);
  }

  h1:not(.title) code {
    font-size: var(--h1-code-font-size);
  }

  h2 {
    font-size: var(--h2-font-size);
    line-height: var(--h2-line-height);
    word-spacing: var(--h2-word-spacing);

    margin-top: var(--h2-margin-top);
    margin-bottom: var(--h2-margin-bottom);
  }

  h2 code {
    font-size: var(--h2-code-font-size);
  }

  h3 {
    font-size: var(--font-size);
    line-height: var(--line-height);
    font-weight: bold;
  }

  h1:not(.title) + *, h1:not(.title) + p { margin-top: var(--h1-margin-bottom); }
  h2 + *, h2 + p                         { margin-top: var(--h2-margin-bottom); }
  h3 + *, h3 + p                         { margin-top: 0; }

  /* }}} */
  /* ----- Prose --------------------------------------------------------- {{{ */

  p, main > ul, main > ol, div.sourceCode, main > pre, img, table {
    margin-top: var(--line-height);
    margin-bottom: var(--line-height)
  }

  ol {
    margin-left: var(--ol-indent-size);
  }

  ul.task-list {
    list-style: none;
    margin-left: var(--ul-indent-size);
  }

  ul.task-list > li {
    position: relative;
  }

  ul.task-list > li > input[type="checkbox"] {
    position: absolute;
    left: calc(-1 * var(--ul-indent-size));
    height: var(--line-height);
  }

  ol > li {
    padding-left: var(--ol-li-padding-left);
  }

  ol                         { list-style-type: decimal; }
  ol ol                      { list-style-type: lower-alpha; }
  ol ol ol                   { list-style-type: lower-roman; }
  ol ol ol ol                { list-style-type: decimal; }
  ol ol ol ol ol             { list-style-type: lower-alpha; }
  ol ol ol ol ol ol          { list-style-type: lower-roman; }
  ol ol ol ol ol ol ol       { list-style-type: decimal; }
  ol ol ol ol ol ol ol ol    { list-style-type: lower-alpha; }
  ol ol ol ol ol ol ol ol ol { list-style-type: lower-roman; }

  ul                         { list-style-type: disc; }
  ul ul                      { list-style-type: circle; }
  ul ul ul                   { list-style-type: square; }
  ul ul ul ul                { list-style-type: disc; }
  ul ul ul ul ul             { list-style-type: circle; }
  ul ul ul ul ul ul          { list-style-type: square; }
  ul ul ul ul ul ul ul       { list-style-type: disc; }
  ul ul ul ul ul ul ul ul    { list-style-type: circle; }
  ul ul ul ul ul ul ul ul ul { list-style-type: square; }

  blockquote {
    border-left: 1px solid var(--color-text-secondary);
    padding-left: 1.5rem;

    font-style: italic;
  }

  blockquote > p {
    margin-top: 0;
  }

  blockquote em, blockquote i, blockquote .sidenote-wrapper {
    font-style: normal;
  }

  hr {
    margin-top: var(--hr-margin-top);
    margin-bottom: var(--hr-margin-bottom);
    border-style: solid;
    color: var(--color-border-heavy);
    border-width: 1px 0 0;
  }

  a code, a:link code, a:visited code,
  a, a:link, a:visited {
    color: var(--color-link);
    text-decoration: none;
  }

  a:hover {
    text-decoration: underline;
  }

  span.mark, mark {
    /* Reset browser styles */
    color: inherit;

    padding: 2px 0 1px;
  }
  span.mark.red,    mark.red    { background-color: var(--highlight-red);    }
  span.mark.yellow, mark.yellow { background-color: var(--highlight-yellow); }
  span.mark.green,  mark.green  { background-color: var(--highlight-green);  }
  span.mark.blue,   mark.blue   { background-color: var(--highlight-blue);   }
  span.mark.purple, mark.purple { background-color: var(--highlight-purple); }

  .subtitle {
    margin-top: 0;
  }
  .author, .date {
    margin-top: 0;
    margin-bottom: 0;
  }
  .signoff {
    margin-top: calc(4 * var(--line-height));
    margin-bottom: calc(4 * var(--line-height));
  }

  /* Pandoc utility classes */
  span.smallcaps{ font-variant: small-caps; }
  span.underline{ text-decoration: underline; }

  .katex-display {
    background: var(--background-color);
    transform: translateZ(0px);
  }

  @media print {
    .katex-display {
      background-color: initial;
    }
  }

  /* }}} */
  /* ----- Code ---------------------------------------------------------- {{{ */

  /* Pandoc code blocks with a language look like div.sourceCode > pre.sourceCode
   * Otherwise, it's just a pre (without .sourceCode)
   *
   * The 'code' element is tricky because it's used for inline code and code in a
   * pre.
   */

  code {
    font-family: var(--font-family-code);

    word-spacing: normal;

    /* Only for inline code */
    color: var(--color-inline-code);
    background-color: var(--color-inline-code-bg);
    font-size: var(--inline-code-font-size);
    margin: 0;
    padding: 2px 0 1px;
    border: 1px solid var(--color-border);
    border-radius: 1px;
  }

  .sidenote code,
  .marginnote code {
    font-size: var(--side-note-code-font-size);
  }

  pre code {
    /* Reset some changes meant to be inline-only */
    color: var(--color-inline-code);
    background-color: var(--color-inline-code-bg);
    font-size: var(--code-block-font-size);
    line-height: var(--line-height);
    margin: initial;
    padding: initial;
    border: initial;
    border-radius: initial;
  }

  pre > code {
    position: relative; /* For line highlights */
    display: inline-block;
    min-width: 100%;
    z-index: 1;

    white-space: pre-wrap;

    padding: 0 var(--code-block-side-padding);
  }

  code.sourceCode::selection {
    /* Prevent bug where far right edge of text box shows as selected. */
    background: transparent;
  }

  .wide > pre, .wide > div.sourceCode {
    /* Put this in front of the table of contents */
    transform: translateZ(0px);
  }

  .wide pre > code {
    white-space: pre;
  }

  pre.numberSource code {
    counter-reset: source-line 0;
  }

  pre > code.sourceCode > span {
    line-height: var(--line-height);

    display: inline-block;
    min-width: 100%;
  }

  div.sourceCode {
    /* Need to make room for line numbers (even if they're not going to be used).
     * Width doesn't matter, just needs to be big enough to hold the largest line
     * number. */
    --line-numbers-width: calc(4 * var(--line-numbers-font-size));
    --line-numbers-negative-width: calc(-1 * var(--line-numbers-width));
    margin-left: var(--line-numbers-negative-width);
  }
  div.sourceCode > pre {
    margin-left: var(--line-numbers-width);
  }
  pre.numberSource > code.sourceCode > span {
    counter-increment: source-line;
    padding-left: var(--line-numbers-width);
    text-indent: var(--line-numbers-negative-width);
    position: relative;
    left: var(--line-numbers-negative-width);
  }
  pre.numberSource > code.sourceCode > span > a:first-child::before {
    -webkit-touch-callout: none;
    -webkit-user-select: none;
    -khtml-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

    content: counter(source-line);
    font-size: var(--line-numbers-font-size);
    text-decoration: none;

    position: relative;
    text-align: right;
    display: inline-block;

    padding: 0 calc(2 * var(--code-block-side-padding));
    width: var(--line-numbers-width);
  }
  pre > code.sourceCode > span > a:first-child::before:hover {
    text-decoration: underline;
  }

  /* Utility class for code blocks that contain things like box drawing characters, where it's nice for things to touch. */
  .tight-code pre,
  pre.tight-code {
    padding-top: var(--tight-code-padding-top);
  }

  pre.tight-code code,
  .tight-code pre code,
  .tight-code pre > code.sourceCode > span,
  pre.tight-code > code.sourceCode > span {
    line-height: var(--tight-code-line-height);
  }

  /* --- Code line highlights --- {{{ */
  /* I used some code I contributed to owickstrom's pandoc-emphasize-code[1] as
   * inspiration for these changes.
   *
   * The novel part is using :nth-of-type(...) selectors and CSS classes, instead
   * of needing a pandoc filter. This means that we can stick with pandoc's
   * default syntax highlighter, and not need to requirer JavaScript for syntax
   * highlighting. It has the obvious limitation that it places a fixed limit on
   * lines that can be highlighted, but these additional CSS styles are easy
   * enough to write, so anyone who needs more lines can write their own
   * stylesheet and include it to add more after the fact.
   *
   * [1] https://github.com/owickstrom/pandoc-emphasize-code/pull/3
   */

  pre > code.sourceCode > span::after {
    position: absolute;
    background-color: var(--color-code-highlight-bg);
    z-index: -1;
    left: calc(var(--line-numbers-width) - var(--code-block-side-padding));
    right: calc(var(--line-numbers-negative-width) - var(--code-block-side-padding));
    top: 0;
    height: 100%;
  }

  pre.hl-1  > code.sourceCode > span:nth-of-type(1)::after  { content: ""; }
  pre.hl-2  > code.sourceCode > span:nth-of-type(2)::after  { content: ""; }
  pre.hl-3  > code.sourceCode > span:nth-of-type(3)::after  { content: ""; }
  pre.hl-4  > code.sourceCode > span:nth-of-type(4)::after  { content: ""; }
  pre.hl-5  > code.sourceCode > span:nth-of-type(5)::after  { content: ""; }
  pre.hl-6  > code.sourceCode > span:nth-of-type(6)::after  { content: ""; }
  pre.hl-7  > code.sourceCode > span:nth-of-type(7)::after  { content: ""; }
  pre.hl-8  > code.sourceCode > span:nth-of-type(8)::after  { content: ""; }
  pre.hl-9  > code.sourceCode > span:nth-of-type(9)::after  { content: ""; }
  pre.hl-10 > code.sourceCode > span:nth-of-type(10)::after { content: ""; }
  pre.hl-11 > code.sourceCode > span:nth-of-type(11)::after { content: ""; }
  pre.hl-12 > code.sourceCode > span:nth-of-type(12)::after { content: ""; }
  pre.hl-13 > code.sourceCode > span:nth-of-type(13)::after { content: ""; }
  pre.hl-14 > code.sourceCode > span:nth-of-type(14)::after { content: ""; }
  pre.hl-15 > code.sourceCode > span:nth-of-type(15)::after { content: ""; }
  pre.hl-16 > code.sourceCode > span:nth-of-type(16)::after { content: ""; }
  pre.hl-17 > code.sourceCode > span:nth-of-type(17)::after { content: ""; }
  pre.hl-18 > code.sourceCode > span:nth-of-type(18)::after { content: ""; }
  pre.hl-19 > code.sourceCode > span:nth-of-type(19)::after { content: ""; }
  pre.hl-20 > code.sourceCode > span:nth-of-type(20)::after { content: ""; }
  pre.hl-21 > code.sourceCode > span:nth-of-type(21)::after { content: ""; }
  pre.hl-22 > code.sourceCode > span:nth-of-type(22)::after { content: ""; }
  pre.hl-23 > code.sourceCode > span:nth-of-type(23)::after { content: ""; }
  pre.hl-24 > code.sourceCode > span:nth-of-type(24)::after { content: ""; }
  pre.hl-25 > code.sourceCode > span:nth-of-type(25)::after { content: ""; }
  pre.hl-26 > code.sourceCode > span:nth-of-type(26)::after { content: ""; }
  pre.hl-27 > code.sourceCode > span:nth-of-type(27)::after { content: ""; }
  pre.hl-28 > code.sourceCode > span:nth-of-type(28)::after { content: ""; }
  pre.hl-29 > code.sourceCode > span:nth-of-type(29)::after { content: ""; }
  pre.hl-30 > code.sourceCode > span:nth-of-type(30)::after { content: ""; }
  pre.hl-31 > code.sourceCode > span:nth-of-type(31)::after { content: ""; }
  pre.hl-32 > code.sourceCode > span:nth-of-type(32)::after { content: ""; }
  pre.hl-33 > code.sourceCode > span:nth-of-type(33)::after { content: ""; }
  pre.hl-34 > code.sourceCode > span:nth-of-type(34)::after { content: ""; }
  pre.hl-35 > code.sourceCode > span:nth-of-type(35)::after { content: ""; }
  pre.hl-36 > code.sourceCode > span:nth-of-type(36)::after { content: ""; }
  pre.hl-37 > code.sourceCode > span:nth-of-type(37)::after { content: ""; }
  pre.hl-38 > code.sourceCode > span:nth-of-type(38)::after { content: ""; }
  pre.hl-39 > code.sourceCode > span:nth-of-type(39)::after { content: ""; }
  pre.hl-40 > code.sourceCode > span:nth-of-type(40)::after { content: ""; }

  /* }}} */

  /* }}} */
  /* ----- Images and figures -------------------------------------------- {{{ */

  /* There's only a figure if there's a caption. Tighten things up. */
  figure {
    margin-bottom: var(--captioned-figure-gap);
  }

  figure + p {
    margin-top: var(--captioned-figure-gap);
  }

  figure > img, figure > pre, figure > div.sourceCode {
    margin-bottom: var(--figcaption-gap);
  }

  img {
    display: block;
  }

  .wide img {
    /* Put this in front of the table of contents */
    transform: translateZ(0px);
  }

  figcaption {
    font-size: var(--figcaption-font-size);
    line-height: var(--figcaption-line-height);
    font-style: italic;
    text-align: center;
    color: var(--color-text-secondary);
  }

  .left-align-caption figcaption {
    text-align: left;
  }

  figcaption code {
    font-size: var(--figcaption-code-font-size);
  }

  /* }}} */
  /* ----- Tables -------------------------------------------------------- {{{ */

  table {
    -webkit-font-feature-settings: "tnum" 1;
    font-feature-settings: "tnum" 1;

    font-size: var(--table-font-size);
    line-height: var(--table-line-height);

    border-spacing: 0;
    border-collapse: collapse;
    border: 1px solid var(--color-border-heavy);

    width: 100%;

    /* Solid background to occlude table of contents */
    background-color: var(--background-color);
  }

  @media print {
    table {
      background-color: initial;
    }
  }

  table code {
    font-size: var(--table-code-font-size);
  }

  table pre code {
    font-size: inherit;
  }

  .wide table {
    /* Put this in front of the table of contents */
    transform: translateZ(0px);
  }

  table td, table th {
    border: 1px solid var(--color-border-heavy);
    padding: 5px 8px;
    min-width: 100px;
  }
  table th {
    background-color: var(--color-table-heading);
  }

  table > caption {
    caption-side: bottom;
    margin-top: var(--figcaption-gap);
    margin-bottom: calc(var(--captioned-figure-gap) - var(--line-height));
    font-size: var(--figcaption-font-size);
    line-height: var(--figcaption-line-height);
    font-style: italic;
    text-align: center;
    color: var(--color-text-secondary);
  }

  .left-align-caption table > caption {
    text-align: left;
  }

  table > caption code {
    font-size: var(--figcaption-code-font-size);
  }

  /* --- Notes are just single cell tables --- */

  .note table {
    font-size: inherit;
    line-height: inherit;
  }
  .note table, .note td {
    border: none;
  }

  .note.red    td { background: var(--highlight-red); }
  .note.yellow td { background: var(--highlight-yellow); }
  .note.green  td { background: var(--highlight-green); }
  .note.blue   td { background: var(--highlight-blue); }
  .note.purple td { background: var(--highlight-purple); }

  /* }}} */
  /* ----- Table of contents --------------------------------------------- {{{ */

  .date.before-toc {
    padding-bottom: var(--line-height);
  }

  nav#TOC label {
    color: var(--color-link);
    cursor: pointer;
  }

  nav#TOC code,
  nav#TOC a,
  nav#TOD a:link,
  nav#TOD a:visited {
    color: var(--color-text-secondary);
  }

  header {
    margin-bottom: var(--line-height);
  }

  .date.before-toc {
    padding-bottom: initial;
  }

  nav#TOC code {
    font-size: var(--nav-toc-code-font-size);
  }

  nav#TOC a:hover,
  nav#TOC a:hover code {
    text-decoration: none;
    color: var(--color-link);
  }

  /* }}} */
  /* ----- Horizontal layouting (main, side notes, extra-wide) ----------- {{{ */

  .sidenote,
  .marginnote {
    float: right;
    clear: right;
    position: relative;

    width: var(--computed-width);
    max-width: var(--side-note-max-width);
    margin-right: calc(-1 * min(var(--computed-width), var(--side-note-max-width)) - var(--margin-left));
  }

  /* --- Side notes and table of contents always visible --- {{{ */

  /* Unfortunately, variables aren't in scope here.
   * 745px = --main-width
   * 52px = 2 * --line-height
   * 206px = side note min width
   */
  @media screen and (min-width: calc(745px + 2 * (52px + 206px + 52px))) {
    header,
    main,
    footer {
      max-width: var(--main-width);
    }

    header,
    main,
    footer {
      margin-left: auto;
      margin-right: auto;
    }

    .sidenote,
    .marginnote {
      --margin-left: calc(2 * var(--line-height));
      --margin-right: var(--margin-left);
      --computed-width: calc((100vw - 100%) / 2 - var(--margin-right) - var(--margin-left));
    }

    .wide {
      width: 100%;
      overflow-x: auto;
    }

    .wide.extra-wide {
      margin-left: calc((1 - var(--extra-wide-scale-factor)) / 2 * 100%);
      width: calc(var(--extra-wide-scale-factor) * 100%);
    }

    .wide.full-width {
      margin-left: calc(var(--line-height) - ((100vw - var(--main-width)) / 2));
      width: calc(100vw - 2 * var(--line-height));
    }

    .wide.extra-wide figcaption,
    .wide.extra-wide table > caption {
      margin-left: calc(((var(--extra-wide-scale-factor) - 1) / 2) * var(--main-width));
      max-width: var(--main-width);
      margin-right: calc(100% - var(--main-width) - (((var(--extra-wide-scale-factor) - 1) / 2) * var(--main-width)));
    }

    .wide.full-width figcaption,
    .wide.full-width table > caption {
      margin-left: calc((100vw - var(--main-width)) / 2 - var(--line-height));
      max-width: var(--main-width);
      margin-right: calc(100% - var(--main-width) - ((100vw - var(--main-width)) / 2 - var(--line-height)));
    }
  }

  /* }}} */
  /* --- Side notes visibile, table of contents collapsed, double-wide margins --- {{{ */

  /* Unfortunately, variables aren't in scope here.
   * 745px = --main-width
   * 52px = 2 * --line-height
   * 206px = side note min width
   */
  @media screen and (min-width: calc(52px + 745px + 52px + 206px + 52px)) and (max-width: calc(745px + 2 * (52px + 206px + 52px) - 1px)) {
    .sidenote,
    .marginnote {
      --margin-left: calc(2 * var(--line-height));
      --margin-right: var(--margin-left);
      --computed-width: calc(100vw - var(--main-width) - calc(2 * var(--line-height)) - var(--margin-right) - var(--margin-left));
    }

    .wide {
      width: 100%;
      overflow-x: auto;
      overflow-y: hidden;
    }

    .wide.extra-wide {
      margin-left: calc(-1 * var(--line-height));
      width: calc(100vw - 2 * var(--line-height));
      max-width: calc(var(--extra-wide-scale-factor) * var(--main-width));
    }

    .wide.full-width {
      margin-left: calc(-1 * var(--line-height));
      width: calc(100vw - 2 * var(--line-height));
      max-width: calc(100vw - 2 * var(--line-height));
    }

    .wide.extra-wide .katex-display,
    .wide.full-width .katex-display {
      padding-left: var(--line-height);
      padding-right: var(--line-height);
    }

    .wide.extra-wide .katex-display,
    .wide.extra-wide .katex-display > .katex,
    .wide.full-width .katex-display,
    .wide.full-width .katex-display > .katex {
      text-align: left;
    }

    .wide.extra-wide figcaption,
    .wide.extra-wide table > caption,
    .wide.full-width figcaption,
    .wide.full-width table > caption {
      text-align: left;
      margin-left: var(--line-height);
      max-width: var(--main-width);
    }
  }

  /* }}} */
  /* --- Side notes visibile, table of contents collapsed --- {{{ */

  /* Unfortunately, variables aren't in scope here.
   * 550px = --main-width-narrow
   * 26px = --line-height
   * 169px = side note min width narrow
   */
  @media screen and (min-width: calc(26px + 550px + 26px + 169px + 26px)) and (max-width: calc(52px + 745px + 52px + 206px + 52px - 1px)) {
    .sidenote,
    .marginnote {
      --margin-left: var(--line-height);
      --margin-right: var(--line-height);
      --computed-width: calc(100vw - var(--main-width-narrow) - var(--line-height) - var(--margin-right) - var(--margin-left));
    }

    .wide {
      width: var(--main-width);
      overflow-x: auto;
      overflow-y: hidden;
    }

    .wide .katex-display,
    .wide .katex-display > .katex {
      text-align: left;
    }

    .wide figcaption,
    .wide table > caption {
      text-align: left;
      max-width: var(--main-width-narrow);
    }

    .wide.extra-wide,
    .wide.full-width {
      width: calc(100vw - 2 * var(--line-height));
    }
  }

  /* }}} */
  /* --- Side notes and table of contents collapsed --- {{{ */

  /* Unfortunately, variables aren't in scope here.
   * See calculations above.
   */
  @media screen and (max-width: calc(26px + 550px + 26px + 169px + 26px - 1px)) {
    .sidenote,
    .marginnote {
      display: none;
    }

    .wide {
      width: 100%;
      overflow-x: auto;
      overflow-y: hidden;
    }

    .wide .katex-display,
    .wide .katex-display > .katex {
      text-align: left;
    }

    .wide figcaption,
    .wide table > caption {
      text-align: left;
      max-width: calc(100vw - 2 * var(--line-height));
    }
  }

  /* }}} */
  /* --- Paged media (print styles) --- {{{ */
  @page {
    size: letter;
    margin: 0.5in;
    /* To make room for line numbers in left margin. */
    margin-left: 0.25in;
  }

  @media print {
    :root {
      --line-height: 18px;
      --font-size: 12px;

      --inline-code-font-size: 11px;
      --code-block-font-size: 10px;
      --code-block-side-padding: 6px;
      --line-numbers-font-size: 8.5px;

      --tight-code-line-height: 12.5px;
      --tight-code-padding-top: 2px;

      --side-note-line-height: 14px;
      --side-note-font-size: 9px;
      --side-note-code-font-size: 9px;
      --side-note-baseline-offset: 3px;
      --side-note-sup-offset: -4px;
      --side-note-number-hang-left: -4px;
      --side-note-text-indent: -6.5px;

      --title-font-size: 30px;
      --title-code-font-size: 29px;
      --title-line-height: 37px;
      --title-margin-top: 71px;

      --h1-font-size: 22px;
      --h1-code-font-size: 20px;
      --h1-line-height: 28px;
      --h1-word-spacing: 0.5px;
      --h1-margin-top: 18px;
      --h1-margin-bottom: 6px;

      --h2-font-size: 16.5px;
      --h2-code-font-size: 15px;
      --h2-line-height: 22px;
      --h2-word-spacing: 0px;
      --h2-margin-top: 14px;
      --h2-margin-bottom: 4.5px;

      --ul-indent-size: 18px;
      --ol-indent-size: 14px;

      --hr-margin-top: 14px;

      --figcaption-line-height: 16px;
      --figcaption-font-size: 10px;
      --figcaption-code-font-size: 9.5px;
      --figcaption-gap: 4.5px;
      --captioned-figure-gap: 7.5px;

      --table-line-height: 16px;
      --table-font-size: 10px;
      --table-code-font-size: 9.5px;

      --nav-toc-font-size: 8.5px;
      --nav-toc-code-font-size: 8.5px;
    }

    body {
      padding-top: 0;
      /* To make room for line numbers in left margin. */
      padding-left: 0.25in;
    }

    .sidenote,
    .marginnote {
      width: 2in;
      margin-right: -2.25in;
    }

    .wide {
      width: 7.5in;
      overflow-x: hidden;
      overflow-y: hidden;
    }

    .wide .katex-display,
    .wide .katex-display > .katex {
      text-align: left;
    }

    .wide figcaption,
    .wide table > caption {
      text-align: left;
      width: 5.25in;
    }

    .wide pre > code {
      white-space: pre-wrap;
    }
  }

  h1, h2, h3 {
    page-break-after: avoid;
  }

  table, figure, pre, img {
    page-break-inside: avoid;
  }
  /* }}} */
  /* }}} */

  /* vim:fdm=marker
   */

  </style>
  <!-- CSS added by filter 'toc-css.lua' for TOC hovering to the side -->
  <!-- TODO: try doing sometthing in px instead of cm to make it more device independent -->
  <style>
  body {
    padding-left: 1.5cm;
    padding-right: 1cm;
    transition: 0.5s;
  }
  nav {
    width: 1cm;
    margin-left: -1.5cm;
    color: grey;
    transition: 0.5s;
    float: left;
    position: fixed;
    top: 0;
    bottom: 0;
    white-space: nowrap;
    overflow: hidden;
    overflow-y: scroll;
    transition: 0.5s;
    z-index: 10;
  }
  nav::-webkit-scrollbar {
    display: none;
  }
  nav a, nav a:visited {
    color: grey;
  }
  nav h2:before {
    content: "≡ ";
    font-size: 150%;
  }
  nav h2:after {
    content: " ◂";
  }
  nav > ul {
    padding-left: 1em;
  }
  nav li {
    margin-left: 1em;
    padding-left: 0;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
  }
  nav ul {
    padding-left: 1em;
    margin-left: 0;
  }
  nav li > a:not(:only-child):before {
    content: "▸ ";
  }
  nav li li li {
    font-size: smaller;
  }
  nav ul li ul  {
    visibility: hidden;
    display: none;
    margin-top: 0.2em;
    margin-bottom: 0.2em;
    transition: 0.5s;
  }
  .paddingleft {
    padding-left: 11cm;
    transition: 0.5s;
  }
  .navside {
    width: 10cm;
    margin-left: -10.5cm;
    padding-right: 1em;
    transition: 0.5s;
  }
  .navside h2:after {
    content: " ▸ ";
  }
  .navshown {
    width: 50%;
    transition: 0.5s;
    background-color: rgba(16, 13, 13, 0.95);
  }
  .subShow > ul {
    visibility: visible;
    display: block;
    transition: 0.5s;
  }
  .subShow > a:not(:only-child):before {
    content: " ▾ ";
  }

  .toc-invisible {
    visibility: hidden;
  }
  .navside > .toc-invisible {
    visibility: visible;
  }
  .navshown > .toc-invisible {
    visibility: visible;
  }
  </style>
</head>
<body>

<header>
<a href="." forTitle="Image Generation">Return to Index</a>
<h1 class="title">Image Generation</h1>
<blockquote class="metadata">
  <p class="date before-toc"><time datetime="Last updated 09/04/2025 at
20:31">Last updated 09/04/2025 at 20:31</time></p>
</blockquote>
</header>

  <nav id="TOC" role="doc-toc">
      <h2 id="toc-title">Contents</h2>
    <ul>
    <li><a href="#how-is-the-ai-trained"
    id="toc-how-is-the-ai-trained">How is the AI trained?</a></li>
    <li><a href="#diffusion-models" id="toc-diffusion-models">Diffusion
    Models</a>
    <ul>
    <li><a href="#noise-v-sampler-steps-scaleguidance-and-seed"
    id="toc-noise-v-sampler-steps-scaleguidance-and-seed">Noise V.
    Sampler: Steps, Scale/Guidance and Seed</a></li>
    <li><a href="#the-limits-of-guidance"
    id="toc-the-limits-of-guidance">The limits of Guidance</a></li>
    <li><a href="#smea" id="toc-smea">SMEA</a></li>
    <li><a href="#decrisper" id="toc-decrisper">Decrisper</a></li>
    <li><a href="#variety-booster" id="toc-variety-booster">Variety
    Booster</a></li>
    </ul></li>
    <li><a href="#tag-based-prompting"
    id="toc-tag-based-prompting">Tag-based Prompting</a>
    <ul>
    <li><a href="#quality-tags-and-aesthetic-tags"
    id="toc-quality-tags-and-aesthetic-tags">Quality Tags And Aesthetic
    Tags</a></li>
    <li><a href="#counting-characters-and-gender"
    id="toc-counting-characters-and-gender">Counting Characters and
    Gender</a></li>
    <li><a href="#character-reference-and-artist-reference"
    id="toc-character-reference-and-artist-reference">Character
    Reference and Artist Reference</a>
    <ul>
    <li><a href="#hallucinated-artists"
    id="toc-hallucinated-artists">"Hallucinated Artists"</a></li>
    </ul></li>
    <li><a href="#tag-interaction" id="toc-tag-interaction">Tag
    Interaction</a>
    <ul>
    <li><a href="#incomplete-interactions"
    id="toc-incomplete-interactions">Incomplete Interactions</a></li>
    <li><a href="#priority-interference"
    id="toc-priority-interference">Priority Interference</a></li>
    <li><a href="#mutual-dependencies"
    id="toc-mutual-dependencies">Mutual Dependencies</a></li>
    <li><a href="#facial-expressions" id="toc-facial-expressions">Facial
    Expressions</a></li>
    </ul></li>
    <li><a href="#strenghtening-and-weakning-math"
    id="toc-strenghtening-and-weakning-math">Strenghtening and Weakning
    Math</a></li>
    <li><a href="#setting-the-base-weighing"
    id="toc-setting-the-base-weighing">Setting the Base
    weighing</a></li>
    <li><a href="#strengthen-autocomplete"
    id="toc-strengthen-autocomplete">Strengthen autocomplete</a></li>
    <li><a href="#strenghtening-value-cheat-sheet"
    id="toc-strenghtening-value-cheat-sheet">Strenghtening value cheat
    sheet</a></li>
    <li><a href="#unwanted-content-or-negative-prompting"
    id="toc-unwanted-content-or-negative-prompting">Unwanted Content, or
    "Negative Prompting"</a></li>
    </ul></li>
    <li><a href="#character-prompting"
    id="toc-character-prompting">Character Prompting</a>
    <ul>
    <li><a href="#per-character-tagging"
    id="toc-per-character-tagging">Per-character Tagging</a></li>
    <li><a href="#positioning" id="toc-positioning">Positioning</a></li>
    <li><a href="#interaction-source-and-target"
    id="toc-interaction-source-and-target">Interaction source and
    target</a></li>
    </ul></li>
    <li><a href="#prose-prompting" id="toc-prose-prompting">Prose
    Prompting</a>
    <ul>
    <li><a href="#referring-to-characters-in-a-prose-prompt"
    id="toc-referring-to-characters-in-a-prose-prompt">Referring to
    Characters in a Prose Prompt</a>
    <ul>
    <li><a href="#story-conversion" id="toc-story-conversion">Story
    Conversion</a></li>
    </ul></li>
    </ul></li>
    <li><a href="#text-on-image-prompting"
    id="toc-text-on-image-prompting">Text-on-image Prompting</a></li>
    <li><a href="#tag-randomization" id="toc-tag-randomization">Tag
    Randomization</a></li>
    <li><a href="#image-to-image-practices"
    id="toc-image-to-image-practices">Image to Image Practices</a></li>
    <li><a href="#bounding--prompting-for-inpainting"
    id="toc-bounding--prompting-for-inpainting">Bounding &amp; Prompting
    for Inpainting</a>
    <ul>
    <li><a href="#bounding" id="toc-bounding">Bounding</a></li>
    <li><a href="#prompting" id="toc-prompting">Prompting</a>
    <ul>
    <li><a href="#clip-interrogator" id="toc-clip-interrogator">CLIP
    Interrogator</a></li>
    <li><a href="#combo-prompting" id="toc-combo-prompting">Combo
    Prompting</a></li>
    </ul></li>
    </ul></li>
    <li><a href="#vibe-transfer" id="toc-vibe-transfer">Vibe
    Transfer</a></li>
    <li><a href="#but-what-about-controlnet-and-loras"
    id="toc-but-what-about-controlnet-and-loras">But what about
    ControlNet? And LoRAs?</a></li>
    <li><a href="#furry-model" id="toc-furry-model">Furry Model</a>
    <ul>
    <li><a href="#tag-differences" id="toc-tag-differences">Tag
    differences</a></li>
    <li><a href="#furry-model-quality-tags-and-unwanted-content"
    id="toc-furry-model-quality-tags-and-unwanted-content">Furry Model
    Quality Tags and Unwanted Content</a></li>
    <li><a href="#artist-tags-for-the-furry-model"
    id="toc-artist-tags-for-the-furry-model">Artist Tags for the Furry
    Model</a></li>
    </ul></li>
    <li><a href="#in-depth-ui-info" id="toc-in-depth-ui-info">In-depth
    UI info</a>
    <ul>
    <li><a href="#anlas-cost-calculation"
    id="toc-anlas-cost-calculation">Anlas Cost Calculation</a></li>
    </ul></li>
    </ul>
  <a href="." forTitle="Image Generation">Return to Index</a>
</nav>

<main>
<p><strong>This guide is focused on nascent technology. As a result,
contents might be highly volatile.</strong></p>
<p>Anlatan already provides an in-depth guide to using their Image
Generation service <a href="https://docs.novelai.net/">here</a>. It is
highly recommended you read it thoroughly because it explains every
functionality and all pieces of the UI in great detail.</p>
<p>You should also read <a
href="https://github.com/TravelingRobot/NAI_Community_Research/wiki/NAI-Diffusion:-Various-Tips-&amp;-Tricks">Traveling
Robot's research notes</a> as well. This guide expounds on some of
them.</p>
<p>This guide aims to provide with more in depth information for power
users.</p>
<p><strong>For people looking for the magic voodoo to create NSFW
artwork: Add NSFW to the prompt. Anywhere.</strong></p>
<h1 id="how-is-the-ai-trained">How is the AI trained?</h1>
<p>The AI was trained on tagged images, based on the Danbooru standard.
Boorus are "imageboards", sites where large amounts of images are saved
in order to catalogue the body of work of artists. This stemmed from a
difficulty to find and archive art reliably, as Japanese artists have a
very different relationship with their works than Western cultures
do.</p>
<p>As a result, these sites were created to host as many images as
possible, and make them easy to find by applying tags. These tags
describe elements of the image, such as character design elements (hair,
eyes, etc), poses, objects, and much more.</p>
<p>There are two parts to training: Quality training, and Aesthetic
training. This will be explained in the next section.</p>
<p>If you are going to go and trawl Danbooru's tag database, keep in
mind that the site is <strong>extremely unsafe for work!</strong></p>
<p>If you are using the Furry model, <strong>you'll need to use E621's
tags.</strong> These can also work on V4, to a degree. This means all
the following information will not work for this specific model. E621 is
just as extremely unsafe for work.</p>
<hr />
<h1 id="diffusion-models">Diffusion Models</h1>
<p>A diffusion model works by resolving noise into an image. If you ever
used a photo editing tool to remove noise from an image, the idea is the
same, except pushed to its logical extreme. You are giving the AI
nothing <em>but</em> noise, and ask it to denoise it into a full
image.</p>
<p>This has several implications:</p>
<p>• The AI has <strong>no grasp</strong> of the position and boundaries
of image elements. It knows what it's trying to make, but it does not
know where things start and end <em>exactly</em>.</p>
<p>• The AI does not have pure semantic understanding of tags. It just
knows that this tag tends to lead to those shapes and those colors. It
does not understand what hair <em>is</em>, but just how it
<em>looks</em> and how it is usually drawn.</p>
<p>• For older models, the AI does not know what applies to what in the
image, this means you can't tell it "I want this, but ONLY for this
character". This is why it can struggle with multiple characters in long
prompts. <strong>For V4, you have character tagging, but it is not
perfect. Sometimes, the character may merge together.</strong></p>
<h2 id="noise-v-sampler-steps-scaleguidance-and-seed">Noise V. Sampler:
Steps, Scale/Guidance and Seed</h2>
<p>Diffusion models work by using Steps to resolve noise. The more
steps, the more compute is used, (which is why the Anlas cost goes up
with steps). Most NAI models were trained from <strong>Stable
Diffusion</strong> models. V4 is an inhouse model.</p>
<p>Steps are carried out by a <strong>Sampler</strong>, which attempts
to resolve the noise based on an algorithm. Each Sampler uses a
different algorithm, and has different results. Some Sampler are
<em>Ancestral</em>, meaning they iterate in a way that performs well at
lower steps more quickly than non-Ancestral samplers.</p>
<p>(That does not mean they perform better <strong>in general</strong>,
just that it costs less to get them to look decent.)</p>
<p>Scale/Guidance affects <em>how much</em> the prompt affects the
Sample steps, but not their "intensity" or their "length". <strong>All
steps are equal in terms of compute</strong>. Guidance thus does
<em>not</em> affect cost.</p>
<p>However, <strong>Negative Guidance Scale</strong> <em>does</em>,
because it uses additional processing power to run <strong>CFG</strong>
or <strong>Classifier-Free Guidance</strong>. If the Negative Guidance
is equal to Positive Guidance, then there is no need for extra compute,
and the cost is the same.</p>
<p><strong>Noise</strong> is the primordial soup from which the AI will
unravel an image. <strong>Seed</strong> is what decides the base noise
pattern, however, <strong>Noise Schedule</strong> in Advanced Settings
changes how that noise is generated and interpreted by the sampler,
resulting in different outputs with the same seed.</p>
<p>Effectively, Noise Schedules are variations of the same Sampler's
algorithm.</p>
<p>For V4, <code>Karras</code> is the default noise scheduler.
<code>native</code>, <code>exponential</code> and
<code>polyexponential</code> are <em>mostly</em> comparable to each
other, with minute differences.</p>
<h2 id="the-limits-of-guidance">The limits of Guidance</h2>
<p>Guidance is nice and all, but V2 and <strong>especially V3 and
V4</strong> work best at a narrow band of scale. V2 works well from 3 to
11, while V3 and V4 works best at 2-6.</p>
<p>Guidance is much stronger on V3 because it uses a different base
model, which is more reactive than V2.</p>
<p>Higher scale leads to stronger contrast, stronger outlines, and all
around stronger "bounding" of elements. This can also cause some
elements to overpower others more readily. This is why low scale is
considered more "painterly", because noise is resolved more loosely,
which leads to the aesthetic "blurriness" of mediums like watercolor,
oil paint, etc.</p>
<p>Addtionally, with multiple character prompts, higher scale may be
preferable.</p>
<p>To allow for a stronger Prompt Guidance without having those issues,
the advanced setting <strong>Prompt Guidance Rescale</strong> attempts
to compensate for them, but this will result in a blurrier output. You
can always use image 2 image to refine the picture once you feel the
base is good enough.</p>
<p>Much like Negative Prompt Guidance, you should adjust Rescale in very
small increments starting from 1. Start in increments of 0.1 or 0.2 with
the same seed, and decide what you prefer from there.</p>
<h2 id="smea">SMEA</h2>
<p>SMEA is an application of Euler Ancestral sampling, but instead of
being applied once per generation, it is applied iteratively, per step.
This can result in increased image quality, and is especially useful at
<strong>larger resolutions than the base resolutions</strong>. SMEA is
used for V1-V3 models, and V4 uses its own solution independently,
meaning it does not require it.</p>
<p>SMEA requires considerably more compute (and its Dynamic version even
moreso), so it will lead to <strong>increased Anlas costs</strong>. The
other issue is that generating with SMEA with the same seed will lead to
very different results than without, so you cannot try and find a good
base cheaply, then regenerate it with SMEA.</p>
<p>As a consequence of how it functions, SMEA reduces the influence of
Guidance. Thus, when turning it on, you should also increase Guidance
slightly to compensate.</p>
<h2 id="decrisper">Decrisper</h2>
<p>When operating at high Scale settings, the aesthetics can get lost as
contrast grows excessive, shapes break apart, and colors leak into the
wrong areas. To correct this, Decrisper dynamically sets thresholds on
the <a href="https://x.com/Birchlabs/status/1582165379832348672">image
latents</a> for every diffusion step, in order to keep them in a more
"expected" space. This helps keep things on track and avoid a breakdown
of style during generation at higher scale. You may require to turn it
on as early as ~7-8 Scale on V3.</p>
<p>Decrisper has no effect on V4 and isn't available for it.</p>
<h2 id="variety-booster">Variety Booster</h2>
<p>A side effect of high scale setting is that the increase in
consistency results in a loss in variety. In order to circumvent that,
you can let the model generate without guidance for a very small amount
of steps, letting it start with a more audacious base, and <em>then</em>
enable guidance and get the positive effects of a higher setting,
without compromising the model's creative abilities.</p>
<p>NovelAI detects when the general composition and body shape (if
applicable) is present, and then enables Guidance for the remainder of
the steps. Keep in mind that this requires your negative prompt to only
kick in at the same time as guidance, so this can lead to it being less
effective, and artifacts or unusual props appearing.</p>
<hr />
<h1 id="tag-based-prompting">Tag-based Prompting</h1>
<p>To use Tags in NAIDiffusion, simply assemble a list of tags freely.
Use commas to separate tags. While tags on Boorus use underscores
instead of spaces, the parser replaced all underscores 'with spaces' to
make it easier to write prompts.</p>
<p>Thus, write prompts with spaces in them if they use multiple words,
and bound them with commas. Forgetting a comma might cause the prompt to
be interpreted incorrectly. <strong>It is important to write your tags
in all lowercase (even for proper nouns) and properly space them, as the
tokenizer will not automatically flatten case or correct spacing. Try to
only use latin characters and punctuation.</strong></p>
<p>When autocompleting tags, a comma will be added automatically.
<strong>Tags do not require underscores, with the exception of facial
expressions like <code>^_^</code>. You should not use underscores
outside of these specific tags.</strong></p>
<p>Keep in mind that most non-latin characters and punctuation will be
turned into <code>UNK</code> tokens. The AI generally interprets those
as tildes or hearts in dialogue.</p>
<p>Something that is important to note is that prompts are interpreted
with linear priority, which is the reverse of text generation. What
comes first has more weight, but the rest is more or less normalized in
strength. It can be useful, or detrimental depending on the result, to
put style, composition, or artist tags at the very beginning of the
prompt, as it will strongly increase their effect.</p>
<p>Tag-based prompts tends to lead to consistent designs. However, they
come out stylistically different and less diverse than Prose-based
prompts.</p>
<p>There are several tag categories that are important to know, due to
how extensively they were used in tagging.</p>
<h2 id="quality-tags-and-aesthetic-tags">Quality Tags And Aesthetic
Tags</h2>
<p>You may have heard of the <code>masterpiece</code> tag being used to
"improve generation quality". This goes a little bit more in depth.</p>
<p>Images were classified according to a percentile "quality score".
Different tags were then applied to training images based on that
score.</p>
<p><strong>For V1</strong>, from highest percentiles to lowest
percentiles:</p>
<p><code>masterpiece, best quality, high quality, normal quality, low quality, worst quality</code></p>
<p><strong>For V2 onwards</strong>, from highest percentiles to lowest
percentiles:</p>
<p><code>best quality, amazing quality, great quality, normal quality, bad quality, worst quality</code></p>
<p>Keep in mind that "amazing quality" incidentally has more NSFW
content, so it may be more appropriate to use for NSFW images, as
opposed to "best quality". (This also explains why it tends to generate
beaches and people in swimsuits.)</p>
<p>If you use any of the Unwanted Content default filters,
<code>worst quality, bad quality,</code> are <strong>automatically
inserted in Unwanted Content</strong>. You can disable the filter or
write them in your prompt to activate them anyway.</p>
<p><strong>Aesthetic tags</strong> are used exclusively in V2 and V3 and
onwards to designate pictures which match the intended "feel" of the
model, as opposed to images that diverge too greatly from the aesthetic
that NovelAI sought. The tags for Aesthetics are:
<code>very aesthetic, aesthetic, displeasing, very displeasing</code></p>
<p>Effectively, displeasing images stray too far from the intended
"look" of NAI Diffusion, or have aesthetics considered "poor" so that
the model knows to avoid them.</p>
<p>You only need one tag for quality and one for aesthtics, though
generally you won't need one. It is better to downbias bad things than
overly bias "good" things, as this may damage creativity. Generally just
using the default Unwanted Content and Quality Tag presets will be
fine.</p>
<h2 id="counting-characters-and-gender">Counting Characters and
Gender</h2>
<p><strong>For V4, this mostly helps for composition. Character tagging
mostly supersedes this, but it can be useful to use gender/number tags
as to ensure consistency.</strong></p>
<p>One of the ubiquitous booru tags is the gender count tag. Whenever
there is a number of characters in frame, then they are counted by
gender.</p>
<p>The tag format is always the same. A number from one to 6 (with a
plus if more than 6), followed immediately by the gender.
<code>1boy, 2girls</code>.</p>
<p>You can also use <code>other</code> as a gender for androgynous or
transgender characters. Generally, they will look rather feminine
nonetheless.</p>
<p>This tag is almost universally put in first position because it
starts with a number rather than a letter, but you can put it anywhere.
Those tags are <strong>very</strong> powerful, so you might not even
need to use them, if you simply describe a character. It is mostly to
make sure you have that number of characters in frame, or reinforce
gender expectations.</p>
<p><strong>However, V4 strongly expects these tags, even if using
multi-character prompts. You should try to include them as a
result.</strong></p>
<p>If you are looking to generate gender noncomforming characters, here
are a few tags.</p>
<p><code>twink, otoko no ko,</code> or <code>1girl, flat chest</code>
can help generate soft boys. (You may need to put <code>breasts</code>
and similar tags in Unwanted Content)</p>
<p><code>toned female, tomboy</code> can help generate butch girls.</p>
<h2 id="character-reference-and-artist-reference">Character Reference
and Artist Reference</h2>
<p>After you specified quality and character number/gender, you'll want
to specify, if applicable, the <strong>Reference Character</strong>,
followed by its <strong>source franchise</strong>. Keep in mind that
Boorus use Japanese name order, meaning that family name comes first for
Japanese characters.</p>
<p><code>yor briar, spy x family</code></p>
<p><code>yamamura sadako, the ring</code></p>
<p>If you wish to use an artist's style, use
<code>artist:(artistname)</code>.</p>
<p>For example, if you want to generate Makoto Kusanagi in the style of
the latest Ghost in the Shell production, you would use:</p>
<p><code>Kusanagi Makoto, ghost in the shell, Artist:Ilya Kuvshinov,</code></p>
<p>You can, of course, put this information anywhere else, this is
simply how file names are generally arranged.</p>
<p><strong>Keep in mind that characters with a low amount of images are
easier to generate on the curated model <em>if</em> their images are
mostly safe for work.</strong></p>
<h3 id="hallucinated-artists">"Hallucinated Artists"</h3>
<p>When using <code>artist:</code> You can add <em>any</em> name as an
artist name, rather than a real one. Sometimes, the effect is quite
remarkable and consistent. Experiment and document those you enjoy
most!</p>
<h2 id="tag-interaction">Tag Interaction</h2>
<p>An easy way to mess up your generations (or improve them!) is to have
tags that interact. One common example of tags overwriting each other is
as follows:</p>
<p><code>1girl, brown hair, blue eyes, sleeping, eyes closed, laying down</code></p>
<p>While the problem is not immediately apparent, specifying an eye
colour <em>and</em> them being closed means that one will be ignored in
favour of the other. <strong>Make sure you don't specify information
about things that are not in frame.</strong> Images on Danbooru follow
the <strong>"tag what you <em>see</em>"</strong> guideline.</p>
<p>A more positive example is:</p>
<p><code>1girl, black hair, blue highlights, blue eyes,</code></p>
<p>Putting a color highlight next to the hair color will give you
colored strands and bangs. Adjust the wording until you get the
specifics you like!</p>
<h3 id="incomplete-interactions">Incomplete Interactions</h3>
<p>Breaking up interactions that occur naturally can result in artifacts
or odd elements. It is easy to achieve if you strengthen a specific part
of a tag rather than the whole tag.</p>
<p><code>1girl, black hair, {{{orange}}} eyes</code></p>
<p>This can lead to the spontaneous appearance of tasty, tasty oranges
everywhere in frame. Whether or not this is a bad thing is up to
you.</p>
<h3 id="priority-interference">Priority Interference</h3>
<p>As tags placed earlier in the prompt have more strength, colors and
other elements tend to leak.</p>
<p><code>blue eyes, black hair</code></p>
<p>Can lead to the hair being tinted blue, or being blue outright. Eyes
tend to have powerful color influence on other elements, as most
character designers tend to match palette to the eyes. Thus, it may be
better to write the hair tags first to avoid that.</p>
<h3 id="mutual-dependencies">Mutual Dependencies</h3>
<p>Some tags implicitly require each other and can lead to artifacts or
tags being ignored if one of them is banned through Undesired Content.
For example, requesting <code>gloves</code> needs hands to be visible,
so if you want no hands in frame, do not request anything that hands
would manipulate or wear, or gestures that require hands to be
performed.</p>
<h3 id="facial-expressions">Facial Expressions</h3>
<p>You'll quickly realize that facial expression tags are non-intuitive
and lead to odd faces. This is because emotions aren't often tagged, and
their vectors are surprisingly strong. Try putting <code>shy</code> in
UC and you'll see what this leads to. Some like <code>pensive</code>
work fine as is.</p>
<p>There are various emotes that can be used as facial expressions, with
fairly strong vectors: <code>:), :(, :3</code> and so on.</p>
<p>Be aware that some, like :|, can break the prompt. Try using an emoji
instead: 😐, or look up the tag database. (For instance, this would be
<code>expressionless</code>)</p>
<p>Having characters look in certain directions also tends to force
certain poses. <code>looking back</code> has a strong tendency to
partially obscure the face with the shoulder, and make the character
bend over.</p>
<h2 id="strenghtening-and-weakning-math">Strenghtening and Weakning
Math</h2>
<p>You may have seen curly braces and square brackets be used to make a
tag stronger or weaker. Here is a more direct explanation.</p>
<p>Each tag has a base value of 1.</p>
<p>If <code>]</code> or <code>{</code> is present, multiply the
<strong>weight multiplier</strong> for all tags following it by 1.05 (a
5% increase). If <code>}</code> or <code>[</code> is present, multiply
the <strong>weight multiplier</strong> for all tags following it by 0.95
(a 5% decrease).</p>
<p>This operation is <strong>multiplicative</strong>, and <strong>make
generations partially non-deterministic.</strong> In the following
examples:</p>
<p><code>blue eyes, black hair</code></p>
<p><code>{[{[blue eyes, black hair]}]}</code> Will lead to different
results on the same seed and settings.</p>
<p>You do not need to close bracket pairs. Hell, you don't even need to
open them!</p>
<p><code>{blue eyes, black hair</code></p>
<p>and</p>
<p><code>]blue eyes, black hair</code></p>
<p>Are fundamentally the same.</p>
<h2 id="setting-the-base-weighing">Setting the Base weighing</h2>
<p>You can directly specify the tag weight by entering a number, then
<strong>two</strong> colons. <code>1.05::</code>, for example, adds 5%
to the weight.</p>
<p>The weight affected by this is the <em>base weight</em>. Weight
affected by braces and brackets is a <em>multiplier</em> that is
calculated <em>on top</em> of the base weight.</p>
<p>This will affect <strong>every tag afterwards</strong> until you
close the weighing section with another pair of colons: <code>::</code>.
which is equivalent to setting the <em>base weight</em> to 1, refer to
the table below for values equivalent to the number of braces you would
have used. <strong>You can have as many decimal places as you want when
specifying your base weight</strong>, technically, but don't overdo it,
or it may break the parser.</p>
<p>e.g. <code>1.2::long hair, blue hair, wavy hair::, blunt bangs</code>
will strengthen everything from long hair to wavy hair, then set the
base weight back to 1.</p>
<p>You can use braces and brackets after setting the base weighing, as
this sets the multiplier, which is then applied to the base weight. i.e
setting the base weight to 1.2 and using a set of braces will do
1.2*1.05.</p>
<p><strong>However, setting the Base Weighing immediately closes braces
and brackets opened before you did so, if they are still
open.</strong></p>
<p>This means that you <strong>shouldn't close</strong> anything you
have opened <strong>before</strong> the base weight setting!</p>
<p><img
src="https://github.com/user-attachments/assets/55782f7c-f523-4ce4-bc92-c7b36a1102fc"
alt="image" /></p>
<p>It will be interpreted as a loose bracket/brace and change the
multiplier once again.</p>
<p>Specifically, it uses this regex for parsing:
<code>-?\d*\.?\d*::</code>. This means that entering <code>-.</code>,
<code>-.::</code>or <code>-::</code>as the value is equivalent to
setting the base weight to 0. <code>::</code> without a value is
equivalent to <code>1::</code>.</p>
<p><strong>If you are weighing prose or anything that ends on a period,
or a number put a space before the closing colons.</strong> This is
because a period followed by two colons will be interpreted as a
zero-weight, and any number will be interpreted as the weight as
well.</p>
<p>i.e <code>1.2::year 2002::</code> will set base weight to 2002 and
cause shenanigans. Do <code>1.2::year 2002 ::</code> instead.</p>
<h2 id="strengthen-autocomplete">Strengthen autocomplete</h2>
<p>You can automatically strengthen a tag by highlighting the entire tag
in the text box, then pressing any <strong>opening</strong> bracket or
curly brace key. It will automatically frame the tag with the type
you've selected. This doesn't work with numerical weighing (yet).</p>
<h2 id="strenghtening-value-cheat-sheet">Strenghtening value cheat
sheet</h2>
<p><img
src="https://github.com/user-attachments/assets/44740f46-86c9-4421-a728-eb57ccd88e11"
alt="image" /></p>
<p>Table graciously provided by <strong>DarkTentacleMaster</strong>!</p>
<p>If you are using <strong>legacy prompt conditioning</strong>, the
model reads the prompt differently. There is no easy explanation for
this that we have access to (even from the devs).Keep in mind the "old"
math is purely here for historical reasons. Only the right side of the
table is in use.</p>
<h2 id="unwanted-content-or-negative-prompting">Unwanted Content, or
"Negative Prompting"</h2>
<p>Unwanted Content is a way to direct the generation away from things
you'd like to avoid. By virtue of how it works, UC is rather
"destructive", so you should keep it as short and focused as possible.
Generate with a short UC, then narrow it down based on what you need per
image.</p>
<p>There are multiple default UC presets, we will focus on V3's
specifically to explain what each element does.</p>
<p>V3</p>
<p>Light:
<code>nsfw, lowres, jpeg artifacts, worst quality, watermark, blurry, very displeasing</code></p>
<p>Heavy:
<code>nsfw, lowres, {bad}, error, fewer, extra, missing, worst quality, jpeg artifacts, bad quality, watermark, unfinished, displeasing, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]</code></p>
<p>Human Focus:
<code>lowres, {bad}, error, fewer, extra, missing, worst quality, jpeg artifacts, bad quality, watermark, unfinished, displeasing, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract], bad anatomy, bad hands, @_@, mismatched pupils, heart-shaped pupils, glowing eyes</code></p>
<ul>
<li>nsfw: Prevents generating explicit pictures without explicit request
from the user.</li>
<li>lowres: Reduces artifacts caused by upscaling low-res images to
larger canvas sizes.</li>
<li>{bad}: Part of several tags such as <code>bad anatomy</code>, used
on its own to avoid using multiple tags starting with "bad", and
including things like <code>bad hands</code> which can result in hands
not being drawn at all.</li>
<li>error, artistic error: Reduces potential artistic mistakes.</li>
<li>fewer, extra and missing: Similar to bad, used to reduce the
occurence of missing digits and limbs, or extraneous anatomy.
<code>extra digits</code> reinforces <code>extra</code> specifically for
hands in order to avoid hands with 6+ fingers.</li>
<li>worst quality and bad quality: Used to tell the model not to
generate images in a similar style to training material with low
score.</li>
<li>jpeg artifacts: Reduces pixelation, palletization and dithering
artifacts caused by heavy JPEG compression.</li>
<li>watermark, signature, username: Reduces text and logo artifacts that
the model cannot generate cleanly.</li>
<li>unfinished: Reduces the frequency of broken, irregular, and missing
outlines. Also tends to reduce the frequency of digits being sketched
but left unfinished.</li>
<li>(very) displeasing: Like <code>worst quality, bad quality</code> but
for Aesthetic tuning.</li>
<li>chromatic aberration: Reduces color artifacting that can occur in
blue, red, and mixed hues thereof. Especially happens on outlines. (This
is an effect similar to Bicolor 3D stereoscopy.)</li>
<li>scan: Reduces scan-induced artifacts such as odd banded lighting and
messy outlines.</li>
<li><code>[abstract]</code>: Reduces overly geometric and amorphous
shaping of objects and people.</li>
<li><code> @_@, mismatched pupils, heart-shaped pupils, glowing eyes</code>:
Several eye-related tags that may incidentally leak into a generation.
Reducing their influence means that eyes should generate "cleaner" most
of the time.</li>
</ul>
<p>== V4 information TBA ==</p>
<hr />
<h1 id="character-prompting">Character Prompting</h1>
<p>V4 allows you to specify prompts <em>per character</em>. The base
prompt will apply to the entire scene.</p>
<h2 id="per-character-tagging">Per-character Tagging</h2>
<p>Each character prompt uses its tags for a single character, this
includes unwanted content. To create a new character prompt, click "Add
Character".</p>
<p><img
src="https://github.com/user-attachments/assets/6634ddc8-d9d9-4686-b0e6-a25eda2e4a96"
alt="image" /></p>
<p>Be mindful that there can be some leakage between characters,
especially when using compositions that focus on a single character,
such as <code>portrait</code>.</p>
<h2 id="positioning">Positioning</h2>
<p>By default, the AI has a general idea of how to position characters
based on what interactions you have specified. Otherwise, you can center
them to a specific 5*5 grid position on the canvas. Be careful not to
forget to adjust it if you have made changes to posing/interaction
tags.</p>
<p>If no positions are specified, the AI will tend to order characters
from <em>top to bottom, left to right</em>.</p>
<h2 id="interaction-source-and-target">Interaction source and
target</h2>
<p>Any interaction such as <code>licking another's face</code> can have
a <strong>Target</strong> and a <strong>Source</strong>. To define the
target, put the tag in their prompt, and append <code>target#</code>
immediately before the tag in question:
<code>target#licking another's face,</code> Source works the same, with
<code>source#</code> instead. You may also use <code>mutual#</code> for
actions that the characters are doing to each other.</p>
<p>Keep in mind that the AI may sometimes mix the roles up and be
confused. Higher Guidance <strong>can</strong> alleviate that, but this
may cause other issues.</p>
<hr />
<h1 id="prose-prompting">Prose Prompting</h1>
<p>To prose-prompt in NAIDiffusion, simply write a sentence describing
the image. Use commas to separate clauses. Try to write neatly with
proper grammar and punctuation, and try to phrase your sentences so that
you use vocabulary close to Booru tags. You can use prose both for scene
(main prompt), or character prompts, but it is more difficult to
reliably describe characters in prose.</p>
<p>It is recommended to use prose to describe scene, image composition
and style. Elements are usually easier to simply tag like usual.</p>
<p>Again, prompts are interpreted with linear priority, which is the
reverse of text generation. What comes first has more weight, so keep
the core content at the beginning of the sentence.</p>
<p>Prose-based prompts tends to lead to more varied output. They are
stylistically different and more diverse than Tag-based prompts, and are
best suited for situations or scenes which are very dynamic and which do
not require consistent character portrayal.</p>
<h2 id="referring-to-characters-in-a-prose-prompt">Referring to
Characters in a Prose Prompt</h2>
<p>When adding character prompts, start them with the name you wish to
use to refer to the character in the prompt. Do not put it in quotes.
You can either follow it with a colon or a comma, but be aware that some
names are valid tags and may be interpreted as such.</p>
<p>After this, use the name at the start of character prompts to refer
to that character in your prose prompt.</p>
<h3 id="story-conversion">Story Conversion</h3>
<p>You can, with some slight adjustments, copy paste excerpts from your
story and use them as prompts. There might be some fine tuning needed,
but you should get something similar to what was described.</p>
<hr />
<h1 id="text-on-image-prompting">Text-on-image Prompting</h1>
<p>You can request V4 to generate text by using
<code>text:your text here.</code></p>
<p>When using Text prompting, write your prompt as normal, and end it on
a period. (<strong>.</strong>) Then, add the text prompting at the very
end of the prompt, after this period.</p>
<p>If you want to have multiple units of text, separate them with a
<strong>linebreak</strong>. Make sure your text units end on a period,
exclamation or question mark if possible.</p>
<p>Both of these examples work, your mileage may vary:</p>
<pre><code>2girls, full body, speech bubble.
Text: Go to bed!
Text: I don&#39;t want to...</code></pre>
<pre><code>2girls, full body, speech bubble, Text: Go to bed!
I don&#39;t want to...</code></pre>
<hr />
<h1 id="tag-randomization">Tag Randomization</h1>
<p>You can randomize a section of your prompt by encasing it with pairs
of pipe characters: <code>||</code>. Once a randomized section is open,
write any tag you want, then add a single pipe <code>|</code> to add
another tag to be randomly selected. Close with another pair of pipe
characters.</p>
<p>You can also only put in part of a tag, if you want to randomize the
color of hair or eyes, for example. Both
<code>||tareme|tsurime|jitome||</code> and
<code>||red|blue|orange|| eyes</code> work.</p>
<p>Remember not to put spaces at the end of a random selection. Just put
it at the end of the entire section so that it formats neatly. That
means <code>||burger |hotdog ||</code> is bad (it'll doublespace).
However something like <code>||red |blue ||eyes</code> works as well.
Just make sure that it leads to a properly spaced prompt after an option
is selected.</p>
<p>You can also have a random "nothing" option by just putting a single
comma as a random selection. <code>||tall|,|short||</code> Double-commas
get purged from the prompt, so this results in a blank if the option is
selected.</p>
<p>You can strengthen and weaken tags inside a random selection just
like anywhere else.</p>
<p>The strengthening will only apply to the selection if it was picked
<em>as long as the brackets or weighing factor is inside the random
selection</em>. Like this: <code>||1.2::tomato::|{{potato}}||</code></p>
<p>Otherwise it'll apply to the entire set of options, like this:
<code>1.2::||foo|bar||::</code> This will apply 1.2 to both options.
(You can still add brackets and braces in there afterwards.)</p>
<p>It is also possible to randomize your weight factor! Try
<code>||1.1::|1.2::|1.3::||</code></p>
<p>After you used a random prompt, check the "Actual Prompt" at the
bottom to get the result with all the final selections only. The rest
will have been purged.</p>
<hr />
<h1 id="image-to-image-practices">Image to Image Practices</h1>
<p>Variations are just Image to Image queued multiple times for the same
image.</p>
<p>Image to Image uses a base image as opposed to Noise. This helps
keeps elements you like in a picture that is good, but not good
<em>enough</em>. Noise adds more noise to the base image, causing it to
change more substantially as you add noise.</p>
<p>Strength is actually, for once, the intensity of the steps. Strong
steps will take more compute (and thus more Anlas).</p>
<p>If your steps and Strength are too low compared to your Noise, your
image will stay noisy, because the noise was not sufficiently resolved!
Make sure you keep the Noise/Processing ratio to a minimum.</p>
<p>Image to Image is best used for the following purposes:</p>
<p>• Fixing a detail that was badly rendered, like an extra finger or a
messed up frill.</p>
<p>○ <em>Recommended edit: Obscure or paint over with surrounding color
palette. 0 noise, 0.2-0.35 strength. (Lower if you trust your
detail-fixing skills better.)</em></p>
<p>• Keeping the same pose but changing lots of misshapen or artifacted
elements.</p>
<p>○ <em>Recommended edit: None. 0-0.1 noise, 0.7-0.85
strength.</em></p>
<p>• Adding a new element to a "good enough" base image.</p>
<p>○ <em>Recommended edit: Draw shape of object using colors similar to
surrounding palette. 0 noise, 0.4-0.6 strength. Keep in mind your image
will look substantially different.</em></p>
<p>• Drawing a foundation for inpainting.</p>
<p>○ <em>Recommended edit: Draw the general shape/background of what you
want. Do not generate a new image. Instead, click "Inpaint image" on the
<strong>left</strong>, and select the area you drew on.</em></p>
<hr />
<h1 id="bounding--prompting-for-inpainting">Bounding &amp; Prompting for
Inpainting</h1>
<h2 id="bounding">Bounding</h2>
<p>Make sure you select areas carefully and include some of the "edges"
of what you're filling in. This will help the generated content "fit in"
better and reduce artifacting. Do not try to select very precisely,
instead, go for clean polygonal shapes.</p>
<p>It is better to inpaint large areas as opposed to small ones, details
are best handled by Image to Image. Very small Inpaint canvases are very
difficult for the AI to handle.</p>
<h2 id="prompting">Prompting</h2>
<p>A common issue that people encounter when inpainting is confusion as
to what you should prompt for.</p>
<p>When inpainting, <strong>only</strong> prompt for what must appear in
the inpainted area. Do not use your full prompt! This may cause the
model to try and cram all these things into the inpainting area, which
will look messy and wrong.</p>
<p>You should avoid using any UC outside of default UC when inpainting
as well, for the same reason.</p>
<hr />
<h3 id="clip-interrogator">CLIP Interrogator</h3>
<p><a
href="https://colab.research.google.com/github/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator.ipynb#scrollTo=YQk0eemUrSC7">Clip
Interrogator</a> can be used to read an image you like and extract tags
and prose that will help you refine your prompt.</p>
<p><strong>V4 does not use CLIP, therefore, this is less useful when
seeking tags for V4.</strong></p>
<h3 id="combo-prompting">Combo Prompting</h3>
<p>If you are generating an image of a specific character that has
trouble coming out consistently, perhaps because there are other
characters with a similar name, you can combine character and franchise
tags in order to obtain something closer to the desired result.</p>
<p><code>sotheby, Reverse:1999,</code></p>
<h1 id="vibe-transfer">Vibe Transfer</h1>
<p>Vibe Transfer is a feature that reads an existing image and attempts
to apply existing elements from it onto a new generation. This is not
<strong>quite</strong> Image to Image, as it lets you generate new
content, rather than mapping off of the existing image.</p>
<p>While this can be compared to <a
href="https://huggingface.co/h94/IP-Adapter">Image Prompt Adapter</a>,
or <a href="https://ieeexplore.ieee.org/document/10377571">Textual
Embedding</a>, Vibe Transfer is its own technology and uses a trained
model. The details are as of yet kept confidential.</p>
<p>Two settings are at play when using Vibe Transfer to prepare a
generation: <strong>Reference Strength</strong> and the
<strong>Information Extracted</strong> Factor.</p>
<p><strong>Reference Strength</strong> is the inverse of Image to Image
Strength. The higher it is, the closer the generation will be to the VT
Reference image. Since the image itself is not used as-is, it will not
be replicated, but excessive strength will cause prompt vectors to be
overpowered by the VT Reference's content, generating something very
similar to it in terms of content, even if you did not prompt for
it.</p>
<p><strong>Information Extracted</strong> is best compared to using a
Magic Wand selector in an image editing software. Instead of selecting
pixels based on color, you select an increasing amount of "meaning" from
the image. It is theorized that simpler elements are included sooner
than more complex ones, but as this is nascent technology, it is unclear
how this proceeds, or if it has any consistency.</p>
<p>Experiment and perhaps contribute your research efforts to this
wiki!</p>
<hr />
<h1 id="but-what-about-controlnet-and-loras">But what about ControlNet?
And LoRAs?</h1>
<p>V4 is an inhouse model, and most plugins are designed for Stable
Diffusion. It's like trying to put an USB key in a HDMI port. Maybe it
looks similar, but it's not going to work. LoRAs are also risky, as they
allow the model to generate content that Anlatan isn't legally allowed
to provide, such as photorealistic renders.</p>
<p>Therefore, be patient, and hope for the team to develop inhouse
tools!</p>
<hr />
<h1 id="furry-model">Furry Model</h1>
<p>The Furry Model is based on a different dataset, and tagging
practices. By default, it is set to a higher Scale setting (6.2) and may
benefit from running at slightly higher Scale than Anime does.</p>
<p><strong>In V4, you can use E621 tags by adding
<code>fur dataset</code> at the start of the prompt.</strong></p>
<h2 id="tag-differences">Tag differences</h2>
<p>The Furry Model uses <a href="https://e621.net/wiki_pages/1671">E621
Tags</a> instead of Danbooru tags. This leads to several important
differences:</p>
<ul>
<li>There is no <code>xGirl</code> or <code>xBoy</code> tags, instead,
you specify <code>male, female, intersex</code>, etc, and then state the
number with <code>solo, duo, group</code></li>
<li>You can specify colors for different body parts more precisely.</li>
<li>Gender tags are different. For instance, <code>intersex</code> is
used rather than <code>futanari</code>, and <code>girly</code> instead
of <code>otoko no ko</code></li>
<li>Some expression and clothing tags are different.</li>
</ul>
<p>Tag for species by preceding them with <code>species:</code> For
example: <code>species: domestic cat</code>.</p>
<h2 id="furry-model-quality-tags-and-unwanted-content">Furry Model
Quality Tags and Unwanted Content</h2>
<p>The default quality tags are the same as for the Anime model, but
strengthened. It is <code>{best quality, amazing quality}</code> added
at the <strong>end</strong> of the prompt.</p>
<p>The light UC is as follows:
<code>nsfw, {worst quality}, guide lines, unfinished, bad, url, tall image, widescreen, compression artifacts, unknown text</code></p>
<p>The Heavy UC is as follows:
<code>nsfw, {{worst quality}}, [displeasing], {unusual pupils}, guide lines, {{unfinished}}, {bad}, url, artist name, {{tall image}}, mosaic, {sketch page}, comic panel, impact (font), [dated], {logo}, ych, {what}, {where is your god now}, {distorted text}, repeated text, {floating head}, {1994}, {widescreen}, absolutely everyone, sequence, {compression artifacts}, hard translated, {cropped}, {commissioner name}, unknown text, high contrast</code></p>
<p>While most of the tags used in the UC are chosen for similar reasons
relative to the Anime UC, there are a few additions that are especially
relevant for this model:</p>
<ul>
<li><code>{unusual pupils}</code>: Reduces eye artifacts. Pupil shape is
highly variable between animals.</li>
<li><code>floating head, guide lines, sketch page, ych, comissioner name,</code>:
Reduces the occurence of unfinished sketch-like drawings often used as
bases for Your Character Here art auctions.</li>
<li><code>comic panel, sequence, impact (font),</code>: Reduces
meme-format leaking.</li>
<li><code>text</code>-related tags and <code>hard translated</code>:
Text and dialogue is frequently present. This helps reduce text-like
artifacts.</li>
<li><code>high contrast</code>: Reduces the likelihood of eye-searing
color palettes.</li>
<li><code>what, where is your god now</code>: tags used for pictures
with especially confusing, abstract, or disturbing/purposefully
offensive subject matters.</li>
<li><code>absolutely everyone</code>: Reduces the likelihood of images
with a mess of blobs that are meant to be a huge crowd of
characters.</li>
<li><code>1994</code>: Unclear, but this year has a substantial amount
of zoo content and pictures with extremely low, MS-paint like
quality.</li>
</ul>
<h2 id="artist-tags-for-the-furry-model">Artist Tags for the Furry
Model</h2>
<p>The Furry model was not trained with artist tags like the Anime model
was. As a result, prompting for <code>artist:artistname</code> will not
result in that artist's style. <strong>However</strong>, any tag you
construct this way <strong>will</strong> have consistent stylistic
results. You just have to invent an artist's name, and document the
results. Hopefully you will find an artist the model "hallucinates" in a
pleasing way.</p>
<h1 id="in-depth-ui-info">In-depth UI info</h1>
<h2 id="anlas-cost-calculation">Anlas Cost Calculation</h2>
<p>The calculation for Anlas cost uses the following algorithms:</p>
<ul>
<li>V1 and V2 (under 1 megapixel for
plms/ddim/k_euler/k_euler_ancestral/k_lms samplers)</li>
</ul>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> width <span class="op">*</span> height  <span class="co"># in pixels</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> r <span class="op">/</span> <span class="dv">1024</span> <span class="op">/</span> <span class="dv">1024</span>  <span class="co"># in megapixels</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>per_image <span class="op">=</span> math.ceil(<span class="fl">15.266497014243718</span> <span class="op">*</span> math.exp(size <span class="op">*</span> <span class="fl">0.6326248927474729</span>) <span class="op">-</span> <span class="fl">15.225164493059737</span>) <span class="op">*</span> steps <span class="op">/</span> <span class="dv">28</span>)</span></code></pre></div>
<p>For V1 and V2 images over 1 megapixel or using other samplers, see
the <a
href="https://github.com/Aedial/novelai-api/blob/2174602d346152d38ce2b43fcec8c9666a72f89a/novelai_api/ImagePreset.py#L588">cost
tables</a>.</p>
<ul>
<li>V3 &amp; V4</li>
</ul>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> width <span class="op">*</span> height  <span class="co"># in pixels</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> smea <span class="kw">and</span> smea_dyn:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    sma_factor <span class="op">=</span> <span class="fl">1.4</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> smea:</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    smea_factor <span class="op">=</span> <span class="fl">1.2</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    smea_factor <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>per_image <span class="op">=</span> math.ceil(<span class="fl">2951823174884865e-21</span> <span class="op">*</span> r <span class="op">+</span> <span class="fl">5.753298233447344e-7</span> <span class="op">*</span> r <span class="op">*</span> steps) <span class="op">*</span> smea_factor</span></code></pre></div>
<p>Strength and uncond scale are then applied to the per_image cost.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>per_image <span class="op">=</span> math.ceil(per_sample <span class="op">*</span> strength)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>per_image <span class="op">=</span> math.<span class="bu">max</span>(per_image, <span class="dv">2</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>per_image <span class="op">=</span> math.ceil(per_image <span class="op">*</span> uncond_scale)</span></code></pre></div>
<p>If the parameters fall within the Opus free image limit, one image is
removed from the cost calculation (only applies for Opus users).</p>

<!-- Javascript added by toc-css.lua to make TOC expandable on click -->
<script>

  const b = document.querySelector("body");
  const n = document.querySelector("nav");
  const buttonsize = 15;

  // click on "toc-title" to show TOC to the side
  document.querySelector("#toc-title").addEventListener("click", function(e) {
    if (e.clientX < e.currentTarget.getBoundingClientRect().left + buttonsize) {
      n.classList.toggle("navshown");
    } else {
      b.classList.toggle("paddingleft");
      n.classList.toggle("navside");
      n.classList.remove("navshown");
    };
  });

  // by default show TOC in large window
  window.onload = function() {
    if (window.innerWidth > 1000) {
      b.classList.add("paddingleft");
      n.classList.add("navside");
    };
  };

  // show/hide TOC on resize
  window.onresize = function () {
    // scrolling on mobile devices triggers resize, so we disable it altogether (for now)
    if (typeof window.orientation !== 'undefined') {
      return;
    };

    if (window.innerWidth > 1000) {
      b.classList.add("paddingleft");
      n.classList.add("navside");
    } else {
      b.classList.remove("paddingleft");
      n.classList.remove("navside");
    };
  };

  // show/hide subsections
  const allLis = document.querySelectorAll("nav li");

  for (const li of allLis) {
    li.addEventListener('click', function (e) {
      // show/hide subsection if arrow is clicked
      if (e.clientX < e.currentTarget.getBoundingClientRect().left + buttonsize
        && e.clientY < e.currentTarget.getBoundingClientRect().top + buttonsize) {

        li.classList.toggle('subShow');
        e.preventDefault();
      };

      // hide full nav if clicked outside
      if (e.currentTarget.getBoundingClientRect().left + 3*buttonsize < e.clientX) {
        n.classList.remove("navshown");
      };
    });

    li.classList.add('subShow');
  };

  // hide ToC if no overruling
  document.querySelector("nav ul").classList.add("toc-invisible");

  // show full nav on tab, hide full nav on escape
  document.addEventListener("keydown", function (e) {
    if (e.which === 27) {
      n.classList.remove("navshown");
      e.preventDefault();
    };
    if (e.which === 9) {
      n.classList.add("navshown");
      e.preventDefault();
    };
  });

  // insert key info
  n.insertAdjacentHTML("beforeend", "<span class='toc-invisible'> \
                                     <br/> \
                                     <p>Press <kbd>Tab</kbd> to show extended width TOC.</p> \
                                     <p>Press <kbd>Esc</kbd> to go back to normal width.</p> \
                                     </span>");

  // hide full nav when clicked outside
  document.addEventListener("click", function(e) {
    if (n.classList.contains("navshown")) {
      if (!n.contains(e.target)) {
        n.classList.remove("navshown");
      };
    };
  });

</script>
</main>

</body>
</html>
